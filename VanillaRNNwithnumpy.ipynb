{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VanillaRNNwithnumpy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAJ628OgrQ8S5t6FXJ5Dc9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afrojaakter/RNN/blob/main/VanillaRNNwithnumpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtpIbwD69e0W"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%pylab inline\n",
        "\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQfg7YFu-18d"
      },
      "source": [
        "#creating training dataset\n",
        "sin_wave = np.array([math.sin(x) for x in np.arange(200)])\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "seq_len = 50\n",
        "num_records = len(sin_wave) - seq_len\n",
        "\n",
        "for i in range(num_records - 50):\n",
        "  X.append(sin_wave[i: i +seq_len])\n",
        "  Y.append(sin_wave[i + seq_len])\n",
        "\n",
        "X = np.array(X)\n",
        "\n",
        "X = np.expand_dims(X, axis = 2) #making a tensor of dim \n",
        "\n",
        "Y = np.array(Y)\n",
        "Y = np.expand_dims(Y, axis = 1)\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgoACwfi8Mkg"
      },
      "source": [
        "#creating validation dataset\n",
        "X_val = []\n",
        "Y_val = []\n",
        "\n",
        "for i in range(num_records - 50, num_records):\n",
        "    X_val.append(sin_wave[i:i+seq_len])\n",
        "    Y_val.append(sin_wave[i+seq_len])\n",
        "    \n",
        "X_val = np.array(X_val)\n",
        "X_val = np.expand_dims(X_val, axis=2)\n",
        "\n",
        "Y_val = np.array(Y_val)\n",
        "Y_val = np.expand_dims(Y_val, axis=1)\n",
        "\n",
        "print(X_val.shape, Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH0dnccT9M1p"
      },
      "source": [
        "####RNN model\n",
        "necessary variables and functions need for the RNN model. Model will take in the input sequence, process it through a hidden layer of 100 units, and produce a single valued output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78SLIBLL8NuA"
      },
      "source": [
        "#Hyper-parameters\n",
        "learning_rate = 0.005\n",
        "nepoch = 25\n",
        "T = 50 #length of the sequence\n",
        "hidden_dim = 100\n",
        "output_dim = 1\n",
        "bptt_truncate = 5\n",
        "min_clip_value = -10\n",
        "max_clip_value = 10"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMtfnomW9vYu"
      },
      "source": [
        "#weight matrix for RNN\n",
        "U = np.random.uniform(0, 1, (hidden_dim, T)) #weight from input to hidden layer\n",
        "W = np.random.uniform(0, 1, (hidden_dim, hidden_dim)) #weight from hidden to output layer\n",
        "V = np.random.uniform(0, 1, (output_dim, hidden_dim)) #shared weight in RNN layer\n",
        "\n",
        "#activation function\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qINS5CEf-1kb"
      },
      "source": [
        "#####Train the model\n",
        "Repeate the following steps until converge\n",
        "1. Check training loss, Forward pass,Calculate Error\n",
        "2. Check validation loss, Forward pass, calculate error\n",
        "3. backpropagate error, update weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHY3T14LK9_z"
      },
      "source": [
        "for epoch in range(nepoch):\n",
        "    # check loss on train\n",
        "    loss = 0.0\n",
        "    \n",
        "    # do a forward pass to get prediction\n",
        "    for i in range(Y.shape[0]):\n",
        "        x, y = X[i], Y[i]                    # get input, output values of each record\n",
        "        prev_s = np.zeros((hidden_dim, 1))   # here, prev-s is the value of the previous activation of hidden layer; which is initialized as all zeroes\n",
        "        for t in range(T):\n",
        "            new_input = np.zeros(x.shape)    # we then do a forward pass for every timestep in the sequence\n",
        "            new_input[t] = x[t]              # for this, we define a single input for that timestep\n",
        "            mulu = np.dot(U, new_input)\n",
        "            mulw = np.dot(W, prev_s)\n",
        "            add = mulw + mulu\n",
        "            s = sigmoid(add)\n",
        "            mulv = np.dot(V, s)\n",
        "            prev_s = s\n",
        "\n",
        "    # calculate error \n",
        "        loss_per_record = (y - mulv)**2 / 2\n",
        "        loss += loss_per_record\n",
        "    loss = loss / float(y.shape[0])\n",
        "\n",
        "    # check loss on val\n",
        "    val_loss = 0.0\n",
        "    for i in range(Y_val.shape[0]):\n",
        "        x, y = X_val[i], Y_val[i]\n",
        "        prev_s = np.zeros((hidden_dim, 1))\n",
        "        for t in range(T):\n",
        "            new_input = np.zeros(x.shape)\n",
        "            new_input[t] = x[t]\n",
        "            mulu = np.dot(U, new_input)\n",
        "            mulw = np.dot(W, prev_s)\n",
        "            add = mulw + mulu\n",
        "            s = sigmoid(add)\n",
        "            mulv = np.dot(V, s)\n",
        "            prev_s = s\n",
        "\n",
        "        loss_per_record = (y - mulv)**2 / 2\n",
        "        val_loss += loss_per_record\n",
        "    val_loss = val_loss / float(y.shape[0])\n",
        "\n",
        "    print('Epoch: ', epoch + 1, ', Train Loss: ', loss[0][0], \n",
        "          ', Val Loss: ', val_loss[0][0])\n",
        "\n",
        "    # train model\n",
        "    for i in range(Y.shape[0]):\n",
        "        x, y = X[i], Y[i]\n",
        "    \n",
        "        layers = []\n",
        "        prev_s = np.zeros((hidden_dim, 1))\n",
        "        dU = np.zeros(U.shape)\n",
        "        dV = np.zeros(V.shape)\n",
        "        dW = np.zeros(W.shape)\n",
        "        \n",
        "        dU_t = np.zeros(U.shape)\n",
        "        dV_t = np.zeros(V.shape)\n",
        "        dW_t = np.zeros(W.shape)\n",
        "        \n",
        "        dU_i = np.zeros(U.shape)\n",
        "        dW_i = np.zeros(W.shape)\n",
        "        \n",
        "        # forward pass\n",
        "        for t in range(T):\n",
        "            new_input = np.zeros(x.shape)\n",
        "            new_input[t] = x[t]\n",
        "            mulu = np.dot(U, new_input)\n",
        "            mulw = np.dot(W, prev_s)\n",
        "            add = mulw + mulu\n",
        "            s = sigmoid(add)\n",
        "            mulv = np.dot(V, s)\n",
        "            layers.append({'s':s, 'prev_s':prev_s})\n",
        "            prev_s = s\n",
        "        # derivative of pred\n",
        "        dmulv = (mulv - y)\n",
        "        \n",
        "        # backward pass\n",
        "        for t in range(T):\n",
        "            dV_t = np.dot(dmulv, np.transpose(layers[t]['s']))\n",
        "            dsv = np.dot(np.transpose(V), dmulv)\n",
        "            \n",
        "            ds = dsv\n",
        "            dadd = add * (1 - add) * ds\n",
        "            \n",
        "            dmulw = dadd * np.ones_like(mulw)\n",
        "\n",
        "            dprev_s = np.dot(np.transpose(W), dmulw)\n",
        "\n",
        "\n",
        "            for i in range(t-1, max(-1, t-bptt_truncate-1), -1):\n",
        "                ds = dsv + dprev_s\n",
        "                dadd = add * (1 - add) * ds\n",
        "\n",
        "                dmulw = dadd * np.ones_like(mulw)\n",
        "                dmulu = dadd * np.ones_like(mulu)\n",
        "\n",
        "                dW_i = np.dot(W, layers[t]['prev_s'])\n",
        "                dprev_s = np.dot(np.transpose(W), dmulw)\n",
        "\n",
        "                new_input = np.zeros(x.shape)\n",
        "                new_input[t] = x[t]\n",
        "                dU_i = np.dot(U, new_input)\n",
        "                dx = np.dot(np.transpose(U), dmulu)\n",
        "\n",
        "                dU_t += dU_i\n",
        "                dW_t += dW_i\n",
        "                \n",
        "            dV += dV_t\n",
        "            dU += dU_t\n",
        "            dW += dW_t\n",
        "\n",
        "            if dU.max() > max_clip_value:\n",
        "                dU[dU > max_clip_value] = max_clip_value\n",
        "            if dV.max() > max_clip_value:\n",
        "                dV[dV > max_clip_value] = max_clip_value\n",
        "            if dW.max() > max_clip_value:\n",
        "                dW[dW > max_clip_value] = max_clip_value\n",
        "                \n",
        "            \n",
        "            if dU.min() < min_clip_value:\n",
        "                dU[dU < min_clip_value] = min_clip_value\n",
        "            if dV.min() < min_clip_value:\n",
        "                dV[dV < min_clip_value] = min_clip_value\n",
        "            if dW.min() < min_clip_value:\n",
        "                dW[dW < min_clip_value] = min_clip_value\n",
        "        \n",
        "        # update\n",
        "        U -= learning_rate * dU\n",
        "        V -= learning_rate * dV\n",
        "        W -= learning_rate * dW\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6-r89YcKlVD"
      },
      "source": [
        "#result on train data\n",
        "preds = []\n",
        "for i in range(Y.shape[0]):\n",
        "    x, y = X[i], Y[i]\n",
        "    prev_s = np.zeros((hidden_dim, 1))\n",
        "    # Forward pass\n",
        "    for t in range(T):\n",
        "        mulu = np.dot(U, x)\n",
        "        mulw = np.dot(W, prev_s)\n",
        "        add = mulw + mulu\n",
        "        s = sigmoid(add)\n",
        "        mulv = np.dot(V, s)\n",
        "        prev_s = s\n",
        "\n",
        "    preds.append(mulv)\n",
        "    \n",
        "preds = np.array(preds)\n",
        "\n",
        "plt.plot(preds[:, 0, 0], 'g')\n",
        "plt.plot(Y[:, 0], 'r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahA6XyfdIIYU"
      },
      "source": [
        "#result on validation data\n",
        "preds = []\n",
        "for i in range(Y_val.shape[0]):\n",
        "    x, y = X_val[i], Y_val[i]\n",
        "    prev_s = np.zeros((hidden_dim, 1))\n",
        "    # For each time step...\n",
        "    for t in range(T):\n",
        "        mulu = np.dot(U, x)\n",
        "        mulw = np.dot(W, prev_s)\n",
        "        add = mulw + mulu\n",
        "        s = sigmoid(add)\n",
        "        mulv = np.dot(V, s)\n",
        "        prev_s = s\n",
        "\n",
        "    preds.append(mulv)\n",
        "    \n",
        "preds = np.array(preds)\n",
        "\n",
        "plt.plot(preds[:, 0, 0], 'g')\n",
        "plt.plot(Y_val[:, 0], 'r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}